---
title: "Take-home Ex 3: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods"
author: "Liang Xiuhao Rydia"
date: "Nov 10, 2024"
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  warning: false
  freeze: true
---

## 1.0 Introduction

### **1.1 The Task**

In this take-home exercise, we are required to calibrate a predictive model to predict HDB resale prices between July-September 2024 by using HDB resale transaction records in 2023.

### 1.2 The Data

Below is the list of data used for this take-home exercise. These data are extracted from data.gov.sg and [LTA Data Mall](https://datamall.lta.gov.sg/content/datamall/en/static-data.html). We will be looking at resale flat that are 4-room, for ease of data manipulation. Similar method could be applied for resale HDB of various size.

-   Structural factors (From resale data)

    -   Area of the unit

    -   Floor level

    -   Remaining lease

    -   Age of the unit

-   Locational factors

    -   Proxomity to CBD

    -   Proximity to eldercare

    -   Proximity to foodcourt/hawker centres

    -   Proximity to MRT

    -   Proximity to park

    -   Proximity to good primary school

    -   Proximity to shopping mall

    -   Proximity to supermarket

    -   Numbers of kindergartens within 350m

    -   Numbers of childcare centres within 350m

    -   Numbers of bus stop within 350m

    -   Numbers of primary school within 1km

## 2.0 Getting Started

### 2.1 Setting up the environment

```{r}
pacman::p_load(sf, tmap,
               spdep, tidyverse,
               httr, jsonlite,
               SpatialAcc, ggstatsplot,
               olsrr, corrplot, ggpubr, 
               GWmodel, tmap,
               DT, plotly, patchwork,
               lwgeom)
```

### 2.2 Importing and Wrangling the Data

Importing all the data into the R environment.

#### 2.2.1 Resale HDB Data

Resale data (3-Room Flat), and transaction between Jan 2023 to Sep 2024. Selecting to retain only relevant fields:

-   Address

-   Postal Code

-   Area of the unit

-   Floor level

-   Remaining lease

-   Age of the unit

-   x-y coordinates (left_join with coordinates extracted through reverse geo-coding with address using onemap API)

```{r}
resale <- read_csv("data/rawdata/resale.csv") %>% 
  filter(flat_type == "3 ROOM") %>%
  filter(month >= "2023-01" & month <= "2024-09") %>%
  mutate(address = paste(block,street_name)) %>%
  mutate(remaining_lease_yr = as.integer(
    str_sub(remaining_lease, 0, 2)))%>%
  mutate(remaining_lease_mth = as.integer(
    str_sub(remaining_lease, 9, 11))) %>%
  separate(storey_range, into = c("min_storey", "max_storey"), sep = " TO ", convert = TRUE) %>%
  mutate(storey_order = as.numeric(min_storey)) %>%
  select(month, resale_price, address, floor_area_sqm, storey_order, remaining_lease_yr, remaining_lease_mth)
```

Extracting the coords:

```{r}
add_list <- sort(unique(resale$address))
```

```{r}
get_coords <- function(add_list){
  
  # Create a data frame to store all retrieved coordinates
  postal_coords <- data.frame()
    
  for (i in add_list){
    #print(i)

    r <- GET('https://www.onemap.gov.sg/api/common/elastic/search?',
           query=list(searchVal=i,
                     returnGeom='Y',
                     getAddrDetails='Y'))
    data <- fromJSON(rawToChar(r$content))
    found <- data$found
    res <- data$results
    
    # Create a new data frame for each address
    new_row <- data.frame()
    
    # If single result, append 
    if (found == 1){
      postal <- res$POSTAL 
      lat <- res$LATITUDE
      lng <- res$LONGITUDE
      new_row <- data.frame(address= i, 
                            postal = postal, 
                            latitude = lat, 
                            longitude = lng)
    }
    
    # If multiple results, drop NIL and append top 1
    else if (found > 1){
      # Remove those with NIL as postal
      res_sub <- res[res$POSTAL != "NIL", ]
      
      # Set as NA first if no Postal
      if (nrow(res_sub) == 0) {
          new_row <- data.frame(address= i, 
                                postal = NA, 
                                latitude = NA, 
                                longitude = NA)
      }
      
      else{
        top1 <- head(res_sub, n = 1)
        postal <- top1$POSTAL 
        lat <- top1$LATITUDE
        lng <- top1$LONGITUDE
        new_row <- data.frame(address= i, 
                              postal = postal, 
                              latitude = lat, 
                              longitude = lng)
      }
    }

    else {
      new_row <- data.frame(address= i, 
                            postal = NA, 
                            latitude = NA, 
                            longitude = NA)
    }
    
    # Add the row
    postal_coords <- rbind(postal_coords, new_row)
  }
  return(postal_coords)
}
```

```{r}
coords <- get_coords(add_list)
```

```{r}
write_rds(coords,"data/rds/coords.rds")
```

```{r}
coords <- read_rds("data/rds/coords.rds")
```

```{r}
resale_xy <- left_join(resale, coords,
                       by = "address") %>% 
  st_as_sf(coords = c("longitude", "latitude"),
                       crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
write_rds(resale_xy, "data/rds/resale_xy.rds")
```

```{r}
resale_xy <- read_rds("data/rds/resale_xy.rds") 
```

#### 2.2.2 Proximity to CBD

![](images/clipboard-1267202484.png)

![](images/clipboard-506858820.png)

![](images/clipboard-2690948445.png)

Based on scribblemaps.com and google map, we can have a sense of Singapore's CBD and Central Area. Central Area includes area spanning Orchard, Chinatown, Marina Bay, Marina East, Bras Basah, Rochor and Newton. For the purpose of this exercise, we will be taking Dhoby Ghaut MRT station(1.299866722252685, 103.8454773226203) as the definition of our centroid of the CBD area for distance calculation purpose. The reason for choosing this point is as such:

1.  Dhoby Ghaut MRT station serves three lines (N-S Line, N-E Line, and Circle Line)
2.  It is approximately central of the Central Area as per the google map.

Another possible centroid would be City Hall MRT(1.2932052372864624, 103.8519615479051), where it serves 2 main MRT lines (N-S Line and E-W Line) and would be representative of centroid when we consider including the Marina Bay East area as part of the Central Area of Singapore.

Next, we will create the sf object for Dhoby Ghaut MRT station.

```{r}
cbd_dg <- data.frame(longitude = "103.8454773226203",
                 latitude = "1.299866722252685") %>% 
  st_as_sf(coords = c("longitude", "latitude"),
                       crs=4326) %>%
  st_transform(crs = 3414)
```

Then, we will check to ensure that both sf data.frame have the same CRS:

```{r}
st_crs(cbd_dg) == st_crs(resale_xy) 
```

Next, we will calculate the distance(in metres) using st_distance and append it back to resale_xy:

```{r}
distances <- st_distance(cbd_dg, resale_xy)
resale_xy$dist_to_cbd <- as.numeric(distances)
```

#### 2.2.3 Proximity to Eldercare

Since there may be multiple eldercare within the area, we will be using the proximity to the nearest available eldercare facility for the resale HDB. ELDERCARE is in shapefile format, hence, we will use st_read() to extract the file as sf data.frame, and also ensure the EPSG code is 3414 using st_transform().

```{r}
eldercare <- st_read(dsn = "data/rawdata", 
                  layer = "ELDERCARE") %>%
  st_transform(crs = 3414) %>% 
  select(geometry)
```

```{r}
st_crs(eldercare)
```

As there are multiple eldercares, we would need to first find the distance matrix, then find the minimum distance amongst all the matrix, and lastly, append the minimum dist back to our resale_xy dataframe.

```{r}
dist_elder <- st_distance(resale_xy,eldercare)
min_distances <- apply(dist_elder, 1, min)
resale_xy$dist_eldercare <- min_distances
```

#### 2.2.4 Proximity to Foodcourt/hawker center

Similar steps are applied to Foodcourt/hawker center.

```{r}
food <- st_read(dsn = "data/rawdata/HawkerCentresKML.kml") %>%
  st_transform(crs = 3414) %>% 
  select(geometry) 
```

```{r}
dist_food <- st_distance(resale_xy,food)
min_distances <- apply(dist_food, 1, min)
resale_xy$dist_food <- min_distances
```

#### 2.2.5 Proximity to MRT

Similar steps are applied to MRT.

```{r}
mrt <- st_read(dsn = "data/rawdata",
               layer = "PassengerPickupBay") %>%
  st_transform(crs = 3414) %>% 
  select("geometry") %>% 
  st_centroid()
```

```{r}
dist_mrt <- st_distance(resale_xy,mrt)
min_distances <- apply(dist_mrt, 1, min)
resale_xy$dist_mrt <- min_distances
```

#### 2.2.6 Proximity to Park

Similar steps are applied to Park. As geojson file contains geometry information with Z-dimension (height), we will use st_zm() to remove this dimensions since we do not need this information.

```{r}
park <- st_read(dsn = "data/rawdata/park.geojson") %>%
  st_zm() %>% 
  st_transform(crs = 3414) %>% 
  select(geometry)
```

```{r}
dist_park <- st_distance(resale_xy,park)
min_distances <- apply(dist_park, 1, min)
resale_xy$dist_park <- min_distances
```

#### 2.2.7 Proximity to a good primary school

Since the definition of a "good" primary school differs, we will use the knowledge from concerned community as the gauge for a "good" primary school. For the purpose of this exercise, I adopted the two definitions that is associated with a "good" primary school:

1.  Special Assistance Plan (SAP) Schools - Cultural Richness in Learning
2.  Gifted Education Programme (GEP) Schools - Tailoring Education for the Gifted

Based on [Creative Campus](https://www.creativecampus.com.sg/best-primary-schools-in-singapore-2024), the list of "good" primary school are compiled in the list named good_sch, using google map to extract the latitude and longitude.

```{r}
good_sch <- data.frame(
  name = c("Ai Tong School", 
           "Anglo-Chinese School (Primary)", 
           "Catholic High School", 
           "CHIJ St., Nicholas Girls’ School", 
           "Henry Park Primary School", 
           "Holy Innocents’ Primary School", 
           "Hong Wen School", 
           "Kong Hwa School", 
           "Maha Bodhi School", 
           "Maris Stella High School (Primary)", 
           "Nan Hua Primary School", 
           "Nanyang Primary School", 
           "Pei Chun Public School", 
           "Pei Hwa Presbyterian Primary School", 
           "Poi Ching School", 
           "Raffles Girls’ Primary School", 
           "Red Swastika School", 
           "Rosyth School", 
           "St. Hilda’s Primary School", 
           "Tao Nan School"),
  latitude = c(1.3605640181003413,
               1.3191507364879236,
               1.355277597260772, 
               1.374247187308568,
               1.3170721007183392, 
               1.366919234532623, 
               1.3216304962516947,
               1.3113035192025317,
               1.3286168882975922,
               1.3413858298053156,
               1.3199812404785924,
               1.3207867963363251,
               1.3373761205768626,
               1.3385314868306721,
               1.3580371568487648,
               1.3302362732220747,
               1.3333982209974653,
               1.3731445652271157,
               1.3498237347980189,
               1.3052062281563859),
  longitude = c(103.83272785347252, 
                103.83577417484831,
                103.84457970481196,
                103.83412198595342,
                103.78415775347251,
                103.8935703058735,
                103.85710945532114,
                103.88815583813025,
                103.90150335711749,
                103.87764453470902,
                103.76203935532115,
                103.80855218230802,
                103.85576078045922,
                103.77617291114346,
                103.9356781534726,
                103.80616995162373,
                103.9341450516237,
                103.8747181976503,
                103.93610449580149,
                103.9114018092948)
  ) %>% 
  st_as_sf(coords = c("longitude", "latitude"),
                       crs=4326) %>%
  st_transform(crs = 3414)
write_rds(good_sch, "data/rds/good_sch.rds")

```

```{r}
dist_good_sch <- st_distance(resale_xy,good_sch)
min_distances <- apply(dist_good_sch, 1, min)
resale_xy$dist_good_sch <- min_distances
```

#### 2.2.8 Proximity to Shopping Mall

Similar steps are applied to Shopping Mall.

```{r}
mall <- st_read(dsn = "data/rawdata",
               layer = "Mall") %>%
  st_transform(crs = 3414) %>% 
  select(geometry)
```

```{r}
dist_mall <- st_distance(resale_xy,mall)
min_distances <- apply(dist_mall, 1, min)
resale_xy$dist_mall <- min_distances
```

#### 2.2.9 Proximity to Supermarket

Similar steps are applied to Supermarket.

```{r}
supermarket <- st_read(dsn = "data/rawdata/SupermarketsKML.kml") %>%
  st_transform(crs = 3414) %>% 
  select(geometry)
```

```{r}
dist_supermarket <- st_distance(resale_xy,supermarket)
min_distances <- apply(dist_supermarket, 1, min)
resale_xy$dist_supermarket <- min_distances
```

#### 2.2.10 Creating buffer of 350m and 1km for resale HDB

```{r}
buffer_350m <- st_buffer(resale_xy, 
                        dist = 350)
```

```{r}
buffer_1km <- st_buffer(resale_xy, 
                        dist = 1000)
```

Importing data for kindergartens, childcare, bus stop, and primary school:

```{r}
kindergarten <- st_read(dsn = "data/rawdata/Kindergartens.kml") %>%
  st_transform(crs = 3414) %>% 
  select(geometry)

childcare <- st_read(dsn = "data/rawdata/ChildCareServices.kml") %>%
  st_transform(crs = 3414) %>% 
  select(geometry)

bus <- st_read(dsn = "data/rawdata",
               layer = "BusStop") %>%
  st_transform(crs = 3414) %>% 
  select(geometry)

pri_sch <- st_read(dsn = "data/rawdata/LTASchoolZoneKML.kml") %>%
  st_transform(crs = 3414)
```

Since the primary school I have got is the a school zone, we will use st_centroid() to find the centroid of each school's location, and use it to calculate distance. We will also need to drop the Z-dimension using st_zm(). Also, to make the name of primary school more readable, we will use sub() of base R to extract the name of the primary school.

```{r}
pri_sch <- pri_sch %>% 
  st_zm() %>% 
  st_centroid() 

pri_sch$Description <- sub(".*<th>SITENAME</th> <td>(.*?)</td>.*", "\\1", pri_sch$Description)

write_rds(pri_sch, "data/rds/pri_sch.rds")
```

#### 2.2.11 Counting the numbers of facilities within the buffers

Counting points for kindergartens, childcare, bus stop, and primary school:

```{r}
resale_xy$kinder_count <- lengths(
  st_intersects(buffer_350m, kindergarten))

resale_xy$childcare_count <- lengths(
  st_intersects(buffer_350m, childcare))

resale_xy$bus_count <- lengths(
  st_intersects(buffer_350m, bus))

resale_xy$pri_sch_count <- lengths(
  st_intersects(buffer_1km, pri_sch))
```

```{r}
write_rds(resale_xy, "data/rds/resale_xy.rds")
```

#### 2.2.12 Importing the Singapore Boundary

```{r}
mpsz = st_read(dsn = "data/rawdata/", 
               layer = "MP14_SUBZONE_WEB_PL") %>% 
  st_transform(crs = 3414)
```

## 3.0 Exploratory Data Analysis (EDA)

### 3.1 HDB Resale Price

```{r}
resale_xy <- read_rds("data/rds/resale_xy.rds")
```

```{r}
ggplot(data=resale_xy, 
       aes(x=`resale_price`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  theme_minimal()
```

From this histogram, we can see the resale price is right skewed, with right tail as high as in the range of \$1.568 million, which is quite a high price for a 3-Room HDB in Singapore. The peak of the histogram is around \$400,000, suggesting the resale price median and mean price is around this value.

Let's take a look at the outliers using the ggplotly.

```{r}
p <- ggplot(data=resale_xy, 
       aes(y=`resale_price`)) +
  geom_boxplot(color="black", 
               fill="light blue") +
  theme_minimal()

ip <- ggplotly(p)
ip
```

From the boxplot, we observe that there's one low outlier price of \$150K, and many high outliers above \$590K (upper quartile).

Next we will take a look at the data above \$590K to determine how we want to treat these outliers.

```{r}
resale_above590k <- resale_xy[resale_xy$resale_price > 590000, ]

datatable(resale_above590k)

```

Investigating the relationship between the resale_price and floor_area_sqm:

```{r}
ggplot(data = resale_xy, 
       aes(x = floor_area_sqm, 
           y = resale_price)) +
  geom_point() +
  geom_smooth(method = "lm", color = "blue", se = FALSE) +  # Adds a trendline
  labs(
    title = "Scatter Plot of Resale Price vs Floor Area with Trendline",
    x = "Floor Area (sqm)",
    y = "Resale Price"
  ) +
  theme_minimal()
```

```{r}
resale_final <- resale_xy %>% 
  filter(resale_price <= 1000000 & floor_area_sqm <= 100) %>% filter(resale_price != 150000)
```

::: callout-important
## Dropping Outliers

-   Lower Outlier of Price \$150k will be dropped.

-   Higher Outliers of location at JLN MA'MOR, JLN BAHAGIA, STIRLING RD seems to have very high resale price and also much higher floor_area_sqm compared to the 60-70 sqm range of a normal 3-Room flat, as well as a remaining_lease_yr in 40 plus years range.

    ![](images/clipboard-1568852073.png)

-   For the high outliers, we will drop the data that has a resale value above \$1mil, more than 100 sqm.
:::

```{r}
a <- ggplot(data=resale_final, 
       aes(x=`resale_price`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  theme_minimal()
```

```{r}
ggplot(data = resale_final, 
       aes(x = floor_area_sqm, 
           y = resale_price)) +
  geom_point() +
  geom_smooth(method = "lm", color = "blue", se = FALSE) +  # Adds a trendline
  labs(
    title = "Scatter Plot of Resale Price vs Floor Area with Trendline",
    x = "Floor Area (sqm)",
    y = "Resale Price"
  ) +
  theme_minimal()
```

```{r}
p <- ggplot(data=resale_final, 
       aes(y=`resale_price`)) +
  geom_boxplot(color="black", 
               fill="light blue") +
  theme_minimal()

ip <- ggplotly(p)
ip
```

```{r}
resale_final <- resale_final %>%
  mutate(`log_resale_price` = log(resale_price))

b <- ggplot(data=resale_final, aes(x=`log_resale_price`)) +
  geom_histogram(bins=20, color="black", fill="light blue") +
  theme_minimal()
```

After applying log to the resale_price, we get a distribution that resemble the

```{r}
a/b
```

```{r}
write_rds(resale_final,"data/rds/resale_final.rds")
```

### 3.2 Drawing Statistical Point Map

```{r}
tm_shape(mpsz) +
  tm_polygons() +
  tm_shape(resale_final) +  
   tm_dots(col = "resale_price",
           alpha = 0.6,
           style = "quantile",
           palette = "Reds") +
   tm_view(set.zoom.limits = c(11, 14))
```

```{r}
tmap_mode("view")

tm_shape(resale_final) +  
   tm_dots(col = "resale_price",
           alpha = 0.6,
           style = "quantile",
           palette = "Reds") 
```

```{r}
tmap_mode("plot")
```

::: callout-note
-   Note that Punggol area has a high concentration of high resale price for 3-room HDB. These are likely newly MOP 3-room flats.
:::

## 4.0 Hedonic Pricing Model for Resale HDB

```{r}
resale_final <- read_rds("data/rds/resale_final.rds")
```

### 4.1 **Multiple Linear Regression Model**

#### 4.1.1 Check Multi-colinearity

```{r}
resale_final <- resale_final %>% 
  mutate(across(c(4, 5, 6, 8, 10:21), as.numeric)) %>% 
  as.data.frame()

corrplot(cor(resale_final[, c(4,5,6, 8, 10:21)]), 
         diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.8,  
         tl.srt = 45,  
         number.cex = 0.5,
         method = "number", type = "upper")  

```

::: callout-important
All correlations values are below 0.8, hence we can conclude that there is no multi-colinearity.
:::

### 4.2 Splitting the Training data and Test data

We will use Jan 2023 to Jun 2024 data as training dataset, and use ground truth of Jul-Sep 2024 to check the performance of the model.

```{r}
train_data <- resale_final %>% 
  st_as_sf() %>% 
  filter(month >= "2023-01" & month <= "2024-06") %>% 
  st_jitter(amount=5)

test_data <- resale_final %>% 
  st_as_sf() %>% 
  filter(month >= "2024-07" & month <= "2024-09") %>% 
  st_jitter(amount=5)
```

```{r}
write_rds(train_data, "data/rds/train_data.rds")
write_rds(test_data, "data/rds/test_data.rds")
```

### 4.3 **Building a non-spatial multiple linear regression**

```{r}
price_mlr <- lm(resale_price ~ floor_area_sqm +
                  + remaining_lease_yr + storey_order +
                  dist_to_cbd + dist_eldercare + dist_food +
                  dist_mrt +dist_park +dist_good_sch +
                  dist_mall + dist_supermarket +
                  kinder_count + childcare_count + bus_count +
                  pri_sch_count,
                data=train_data)
summary(price_mlr)
```

::: callout-note
-   All predictors have p-value lesser than alpha = 0.05, meaning all are statistically significant, except eldercare, with a p-value of 0.284436.

-   Adjusted R-squared is 0.7334, suggesting a strong model with 73.34% of the variance in the resale prices is explained by the predictors.

-   The model also has p-value lesser than alpha = 0.05, suggesting that this model is statistically significant.
:::

```{r}
write_rds(price_mlr, "data/model/price_mlr.rds" ) 
```

### 4.4 GWR Predictive Model

```{r}
train_data_sp <- as_Spatial(train_data)
# Extract coordinates from the SpatialPointsDataFrame
coords <- coordinates(train_data_sp)

# Check for duplicates in the coordinates
duplicate_indices <- which(duplicated(coords))

# Print duplicate coordinates and their indices
if (length(duplicate_indices) > 0) {
  cat("Duplicate points found at indices:\n")
  print(duplicate_indices)
  print(coords[duplicate_indices, ])
} else {
  cat("No duplicate points found.")
}

```

```{r}
test_data_sp <- as_Spatial(test_data)

# Extract coordinates from the SpatialPointsDataFrame
coords <- coordinates(test_data_sp)

# Check for duplicates in the coordinates
duplicate_indices <- which(duplicated(coords))

# Print duplicate coordinates and their indices
if (length(duplicate_indices) > 0) {
  cat("Duplicate points found at indices:\n")
  print(duplicate_indices)
  print(coords[duplicate_indices, ])
} else {
  cat("No duplicate points found.")
}

```

```{r}
plot(train_data_sp, col = 'blue', pch = 16, main = "Training and Test Points")
points(test_data_sp, col = 'red', pch = 16)
legend("topright", legend = c("Train", "Test"), col = c("blue", "red"), pch = 16)

```

#### 4.4.1 Computing Adaptive Bandwidth

Removing dist_eldercare from the model:

```{r}
bw_adaptive <- bw.gwr(resale_price ~ floor_area_sqm +
                  + remaining_lease_yr + storey_order +
                  dist_to_cbd + dist_food +
                  dist_mrt +dist_park +dist_good_sch +
                  dist_mall + dist_supermarket +
                  kinder_count + childcare_count + bus_count +
                  pri_sch_count,
                  data=train_data_sp,
                  approach="CV",
                  kernel="gaussian",
                  adaptive=TRUE,
                  longlat=FALSE)
```

```{r}
write_rds(bw_adaptive, "data/model/bw_adaptive.rds")
```

#### 4.4.2 **Constructing the adaptive bandwidth gwr model**

```{r}
bw_adaptive <- read_rds("data/model/bw_adaptive.rds")
```

The result shows that 49 neighbour points will be the optimal bandwidth to be used if adaptive bandwidth is used for this data set.

```{r}
bw_adaptive
```

Using the derived adaptive bandwidth for gwr-based pricing model

```{r}
gwr_adaptive <- gwr.basic(formula = resale_price ~ floor_area_sqm +
                  + remaining_lease_yr + storey_order +
                  dist_to_cbd + dist_food +
                  dist_mrt +dist_park +dist_good_sch +
                  dist_mall + dist_supermarket +
                  kinder_count + childcare_count + bus_count +
                  pri_sch_count,
                          data=train_data_sp,
                          bw=bw_adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE,
                          longlat = FALSE)
```

```{r}
write_rds(gwr_adaptive, "data/model/gwr_adaptive.rds")
```

#### 4.4.3 Retrieving gwr output object

```{r}
gwr_adaptive <- read_rds("data/model/gwr_adaptive.rds")
```

```{r}
gwr_adaptive
```

::: callout-important
-   Adjusted R-square is 0.931709, which indicates that the GWR model is improved from the general multiple linear regression.
:::

#### 4.4.4 **Computing adaptive bandwidth for the test data**

```{r}
bw_adaptive_test <- bw.gwr(resale_price ~ floor_area_sqm +
                  + remaining_lease_yr + storey_order +
                  dist_to_cbd + dist_food +
                  dist_mrt +dist_park +dist_good_sch +
                  dist_mall + dist_supermarket +
                  kinder_count + childcare_count + bus_count +
                  pri_sch_count,
                  data=test_data_sp,
                  approach="CV",
                  kernel="gaussian",
                  adaptive=TRUE,
                  longlat=FALSE)
```

```{r}
bw_adaptive_test
```

Adaptive bandwidth to be used for test data is 33

### **14.8.7 Computing predicted values of the test data**

```{r}
gwr_pred <- gwr.predict(formula = resale_price ~ floor_area_sqm +
                  + remaining_lease_yr + storey_order +
                  dist_to_cbd + dist_food +
                  dist_mrt +dist_park +dist_good_sch +
                  dist_mall + dist_supermarket +
                  kinder_count + childcare_count + bus_count +
                  pri_sch_count, 
                  data=train_data_sp, 
                  predictdata = test_data_sp, 
                  bw=bw_adaptive, 
                  kernel = 'gaussian', 
                  adaptive=TRUE, 
                  longlat = FALSE)
```

## 4.5 Random Forest Model
