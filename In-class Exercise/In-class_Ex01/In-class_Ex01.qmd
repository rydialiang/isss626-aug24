---
title: "In-class Ex 01 "
author: "Liang Xiuhao Rydia"
date: "Aug 26, 2024"
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  message: false
  freeze: true
format: 
  html:
    code-fold: true
    code-summary: "Show the code"
---

![](images/clipboard-330117975.png)

## 1.0 Loading Library and Data

This code chunk install and load the relevant package.

```{r}
pacman::p_load(tidyverse,sf,
               tmap,ggstatsplot)
```

## 2.1 Working with Master Plan Planning Sub-zone Data

This code chunk imports shapefile(.shp):

```{r}
mpsz14_shp = st_read(dsn = "data/", 
                  layer = "MP14_SUBZONE_WEB_PL")
```

This code chunk imports kml file(.kml):

```{r}
st_write(mpsz14_shp,
         "data/MP14_SUBZONE_WEB_PL.kml",
         delete_dsn = TRUE)
```

::: callout-note
-   for "delete_dsn" argument = TRUE, the file of the same name (mpsz14_shp) will be overwritten by the new file.
:::

## 2.2 Working with Pre-school Location Data

This code chunk imports kml file.

```{r}
preschool_kml <- st_read("data/PreSchoolsLocation.kml")
```

This code chunk imports geojson file.

```{r}
preschool_geojson <- st_read("data/PreSchoolsLocation.geojson") 
```

## 2.3 Working with Master Plan 2019 Subzone Boundary Data

This code chunk import shapefile.

```{r}
mpsz19_shp <- st_read(dsn = "data/",
                layer = "MPSZ-2019")
```

This code chunk import kml file:

```{r}
mpsz19_kml <- st_read("data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml")
```

## 3.0 Handling Coordinate Systems

### 3.1 Checking coordinate system

```{r}
st_crs(mpsz19_shp)
```

::: callout-note
-   Note that the EPSG code is 4326 for WGS84.

-   We may need to perform transformation to change the EPSG code accordingly if we notice that the EPSG code does not corresponding to the CRS.

-   The correct EPSG code for svy21 should be [3414](https://epsg.io/3414).
:::

### 3.2 Transformation / Re-projection

Import and transform coordinate system for the shapefile:

```{r}
mpsz19_shp <- st_read(dsn = "data/",
                  layer = "MPSZ-2019") %>% 
  st_transform(crs = 3414)
```

::: callout-note
### Geographical Coordinate Systems

-   GCS define locations on the earth using a three-dimensional spherical surface. For example, WGS84.

-   They provides accuracy position information. Unit of measurement will be in either decimal degree or degree-minute-second format.

-   GCS, however, are not appropriate for distance and area measurements. In this figure, it is clear that 1 degree distance at the north pole is relatively shorter than 1 degree at the equator.

-   Refer to [9.1 Geographic Coordinate Systems](https://mgimond.github.io/Spatial/chp09_0.html#geographic-coordinate-systems) to learn more about GCS.
:::

::: callout-note
### Projected Coordinate Systems (PCS)

-   Based on a map projection such as transverse Mercator, Albers equal area, or Robinson.

-   PCS provides consistent length and area measurement across space. Hence, it is important to transform a geospatial data from GCS to PCS before performing geospatial analysis.

-   Refer to [9.2 Projected Coordinate Systems](https://mgimond.github.io/Spatial/chp09_0.html#projected-coordinate-systems) to learn more about GCS.
:::

::: callout-note
## Transformation (st_transform)

-   technical term: re-projection

-   mpsz19_shp geometry changed.

-   Before:

    ![](images/clipboard-21986329.png)

-   After:

    ![](images/clipboard-1838988116.png)
:::

Import and transform kml file:

```{r}
preschool <- st_read("data/PreSchoolsLocation.kml") %>%
  st_transform(crs = 3414)
```

::: callout-note
## Note on CSV and Excel file

We may prefer to work with csv file as it is tidier. Excel file may contain headers and merged cell, which may result in requirement for data cleaning.
:::

## 4.0 Geospatial Data Wrangling

### 4.1 Point-in-Polygon count

The code chunk below count the number of pre-schools in each planning sub-zone.

```{r}
mpsz19_shp <- mpsz19_shp %>%
  mutate(`PreSch Count` = lengths(
    st_intersects(mpsz19_shp, preschool)))
```

::: callout-note
## Recap on st_intersects / st_intersection

-   *st_intersects*: touch or overlap. This [commands](https://r-spatial.github.io/sf/reference/geos_binary_pred.html) compare two sf data object and return a sparse matrix with matching (TRUE) indexes, or a full logical matrix.

-   st_intersection: intersection of pairs of geometries. This command overlay two sf data frames.
:::

### 4.2 Computing Density

The code chunk below performs the following tasks:

-   Derive the area of each planning sub-zone.

-   Drop the unit of measurement of the area (i.e. m\^2)

-   Calculate the density of pre-school at the planning sub-zone level.

```{r}
mpsz19_shp <- mpsz19_shp %>%
  mutate(Area = units::drop_units(
    st_area(.)),
    `PreSch Density` = `PreSch Count` / Area * 1000000
  )
```

## 5.0 Statistical Analysis

The tasks: Using appropriate Exploratory Data Analysis (EDA) and Confirmatory Data Analysis (CDA) methods to explore and confirm the statistical relationship between Pre-school Density and Pre-school count.

Tip: Refer to [`ggscatterstats()`](https://indrajeetpatil.github.io/ggstatsplot/articles/web_only/ggscatterstats.html) of **ggstatsplot** package.

```{r}
mpsz19_shp$`PreSch Density` <- as.numeric(as.character(mpsz19_shp$`PreSch Density`))
mpsz19_shp$`PreSch Count` <- as.numeric(as.character(mpsz19_shp$`PreSch Count`)) 
mpsz19_shp_1 <- as.data.frame(mpsz19_shp)

ggscatterstats(data = mpsz19_shp_1,
               x = `PreSch Density`,
               y = `PreSch Count`,
               type = "parametric",
               label.var = `SUBZONE_N`,
               label.expression =  `PreSch Density` > 30 |`PreSch Count` > 50) 
```

## 6.0 Working with Population Data

The code chunk below import the csv file:

```{r}
popdata <- read_csv("data/respopagesextod2023.csv")
```

## 6.1 Data Wrangling

Prepare a data.frame showing population by Planning Area and Planning subzone.

```{r}
popdata2023 <- popdata %>% 
  group_by(PA, SZ, AG) %>% 
  summarise(`POP`=sum(`Pop`)) %>%  
  ungroup() %>% 
  pivot_wider(names_from=AG,
              values_from = POP)

colnames(popdata2023)
```

### 6.1.1 Derive New Fields

Derive a tibble data.framewith the following fields PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY where by:

-   YOUNG: age group 0 to 4 until age groyup 20 to 24,

-   ECONOMY ACTIVE: age group 25-29 until age group 60-64,

-   AGED: age group 65 and above,

-   TOTAL: all age group, and

-   DEPENDENCY: the ratio between young and aged against economy active group.

```{r}
popdata2023 <- popdata2023 %>%
  mutate(YOUNG=rowSums(.[3:6]) # Aged 0 - 24, 10 - 24
         +rowSums(.[14])) %>% # Aged 5 - 9
  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+ # Aged 25 - 59
  rowSums(.[15])) %>%  # Aged 60 -64
  mutate(`AGED`=rowSums(.[16:21])) %>%
  mutate(`TOTAL`=rowSums(.[3:21])) %>%
  mutate(`DEPENDENCY`=(`YOUNG` + `AGED`)
  / `ECONOMY ACTIVE`) %>% 
  select(`PA`, `SZ`, `YOUNG`, 
         `ECONOMY ACTIVE`, `AGED`,
         `TOTAL`, `DEPENDENCY`)
```

::: callout-caution
-   Take note of the column number for each age group. Some do not run in sequence.

    -   Aged 5 - 9: Column 14

    -   Aged 60 -64: Column 15
:::

### 6.1.2 Joining popdata2023 and mpsz19_shp.

Using dplyr::mutate_at() to change to uppercase:

```{r}
popdata2023 <- popdata2023 %>%
  mutate_at(.vars = vars(PA, SZ), 
          .funs = list(toupper)) 
```

Combining using left_join():

```{r}
mpsz_pop2023 <- left_join(mpsz19_shp, popdata2023,
                          by = c("SUBZONE_N" = "SZ"))

```

```{r}
pop2023_mpsz <- left_join(popdata2023, mpsz19_shp, 
                          by = c("SZ" = "SUBZONE_N"))
```

::: callout-note
-   Sequence of the left_join() will determine the order of the columns in the new data.frame.

-   The data.frame columns will be added in the same sequence as in the left_join() arguments.

    -   i.e. mpsz_pop2023 df will have SUBZONE_N as the first column followed by all other columns in mpsz, then followed by columns in the pop2023.

-   pop2023_mpsz will have PA as the first column, followed by all other columns in pop2023, then followed by columns in the mpsz.
:::

## 7.0 Choropleth Map of Dependency Ratio by Planning Subzone

```{r}
tmap_style("white")
```

```{r}
tm_shape(mpsz_pop2023)+
  tm_fill("DEPENDENCY", 
          style = "quantile", 
          palette = "Blues",
          title = "Dependency ratio") +
  tm_layout(main.title = "Distribution of Dependency Ratio by planning subzone",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE,
            bg.color = "#FFE5CC") +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar(position = c("center", "bottom")) +
  tm_grid(alpha =0.2) +
  tm_credits("Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\n and Population data from Department of Statistics DOS", 
             position = c("left", "top"))
  
```

## 8.0 Analytical Map: Percentile Map

### 8.1 The concept

The percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.

### 8.2 Step 1: Data Preparation

The code chunk below excludes records with NA by using the code chunk below.

```{r}
mpsz_pop2023 <- mpsz_pop2023 %>%
  drop_na()
```

### 8.3 Step 2: The get function

The code chunk below defines a function to get the input data and field to be used for creating the percentile map.

```{r}
get.var <- function(vname,df) {
  v <- df[vname] %>% 
    st_set_geometry(NULL)
  v <- unname(v[,1])
  return(v)
}
```

### 8.4 Step 3: A percentile mapping function

The code chunk below creates a function for computing and plotting the percentile map.

```{r}
percentmap <- function(vnam, df, legtitle=NA, mtitle="Percentile Map"){
  percent <- c(0,.01,.1,.5,.9,.99,1)
  var <- get.var(vnam, df)
  bperc <- quantile(var, percent)
  tm_shape(mpsz_pop2023) +
  tm_polygons() +
  tm_shape(df) +
     tm_fill(vnam,
             title=legtitle,
             breaks=bperc,
             palette="Blues",
          labels=c("< 1%", "1% - 10%", "10% - 50%", "50% - 90%", "90% - 99%", "> 99%"))  +
  tm_borders() +
  tm_layout(main.title = mtitle, 
            title.position = c("right","bottom"))
}
```

### 8.5 Step 4: Running the functions

The code chunk below runs the percentile map function.

```{r}
percentmap("DEPENDENCY", mpsz_pop2023)
  
```

## 9.0 Analytical Map: Box Map

### The Concept

In essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).

```{r}
ggplot(data = mpsz_pop2023,
       aes(x = "",
           y = DEPENDENCY)) +
  geom_boxplot()
```

### 9.1 Step 1: Creating the boxbreaks function

The code chunk on the right is an R function that creating break points for a box map.

-   arguments:

    -   v: vector with observations

    -   mult: multiplier for IQR (default 1.5)

-   returns:

    -   bb: vector with 7 break points compute quartile and fences

```{r}
boxbreaks <- function(v,mult=1.5) {
  qv <- unname(quantile(v))
  iqr <- qv[4] - qv[2]
  upfence <- qv[4] + mult * iqr
  lofence <- qv[2] - mult * iqr
  # initialize break points vector
  bb <- vector(mode="numeric",length=7)
  # logic for lower and upper fences
  if (lofence < qv[1]) {  # no lower outliers
    bb[1] <- lofence
    bb[2] <- floor(qv[1])
  } else {
    bb[2] <- lofence
    bb[1] <- qv[1]
  }
  if (upfence > qv[5]) { # no upper outliers
    bb[7] <- upfence
    bb[6] <- ceiling(qv[5])
  } else {
    bb[6] <- upfence
    bb[7] <- qv[5]
  }
  bb[3:5] <- qv[2:4]
  return(bb)
}
```

### 9.2 Step 2: Creating the get.var function

The code chunk on the right an R function to extract a variable as a vector out of an sf data frame.

-   arguments:

    -   vname: variable name (as character, in quotes)

    -   df: name of sf data frame

-   returns:

    -   v: vector with values (without a column name)

```{r}
get.var <- function(vname,df) {
  v <- df[vname] %>% st_set_geometry(NULL)
  v <- unname(v[,1])
  return(v)
}
```

### 9.3 Step 3: Boxmap function

The code chunk on the right is an R function to create a box map.

-   arguments:

    -   vnam: variable name (as character, in quotes)

    -   df: simple features polygon layer

    -   legtitle: legend title

    -   mtitle: map title

    -   mult: multiplier for IQR

-   returns:

    -   a tmap-element (plots a map)

```{r}
boxmap <- function(vnam, df, 
                   legtitle=NA,
                   mtitle="Box Map",
                   mult=1.5){
  var <- get.var(vnam,df)
  bb <- boxbreaks(var)
  tm_shape(df) +
    tm_polygons() +
  tm_shape(df) +
     tm_fill(vnam,title=legtitle,
             breaks=bb,
             palette="Blues",
          labels = c("lower outlier", 
                     "< 25%", 
                     "25% - 50%", 
                     "50% - 75%",
                     "> 75%", 
                     "upper outlier"))  +
  tm_borders() +
  tm_layout(main.title = mtitle, 
            title.position = c("left",
                               "top"))
}
```

### 9.4 Step 4: Plotting Box Map

```{r}
boxmap("DEPENDENCY", mpsz_pop2023)
```

### 9.5 Plotting Interactive Box Map

```{r}
tmap_options(check.and.fix = TRUE)
tmap_mode("view")
boxmap("DEPENDENCY", mpsz_pop2023)
```

## 10 Reference

Prof T.S. Kam: Geospatial Analytics & Application [In-Class Ex 01](https://isss626-ay2024-25aug.netlify.app/in-class_ex/in-class_ex01/in-class_ex01#/title-slide)
